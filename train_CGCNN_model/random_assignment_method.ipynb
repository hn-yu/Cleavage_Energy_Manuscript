{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import all packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import multiprocess as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import tqdm\n",
    "import torch\n",
    "import skorch.callbacks.base\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, 'adamwr') # you will need to have adamW optimizer cloned locally\n",
    "sys.path.insert(0, 'cgcnn/')\n",
    "import cgcnn\n",
    "import mongo\n",
    "\n",
    "from cgcnn.data import collate_pool, MergeDataset, StructureDataTransformer\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skorch.callbacks import Checkpoint, LoadInitState \n",
    "from skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "from skorch.dataset import ValidSplit\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "# from cosine_scheduler import CosineLRWithRestarts\n",
    "# from adamw import AdamW\n",
    "from torch.optim import AdamW\n",
    "\n",
    "#Select which GPU to use if necessary\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the cleavage energy docs and convert the structures into graph objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pickle.load(open('../cleavage_energy_dataset/intermetallics_cleavage_energy_data.pkl' ,'rb'))\n",
    "random.seed(123)\n",
    "random.shuffle(docs)\n",
    "\n",
    "for doc in docs:\n",
    "    doc[\"atoms\"] = doc['thinnest_structure']['atoms']\n",
    "    doc[\"results\"] = doc['thinnest_structure']['results']\n",
    "    doc[\"initial_configuration\"] = doc['thinnest_structure']['initial_configuration']\n",
    "    del doc[\"thinnest_structure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3033 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SDT_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\multiprocess\\pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_32836\\2470345216.py\", line 21, in <lambda>\nNameError: name 'SDT_out' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m SDT_out \u001b[38;5;241m=\u001b[39m SDT\u001b[38;5;241m.\u001b[39mtransform(docs)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m---> 21\u001b[0m     SDT_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSDT_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSDT_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSDT_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\multiprocess\\pool.py:423\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    415\u001b[0m result \u001b[38;5;241m=\u001b[39m IMapIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_taskqueue\u001b[38;5;241m.\u001b[39mput(\n\u001b[0;32m    417\u001b[0m     (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guarded_task_generation(result\u001b[38;5;241m.\u001b[39m_job,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m         result\u001b[38;5;241m.\u001b[39m_set_length\n\u001b[0;32m    422\u001b[0m     ))\n\u001b[1;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (item \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m chunk)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\multiprocess\\pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SDT_out' is not defined"
     ]
    }
   ],
   "source": [
    "SDT = StructureDataTransformer(atom_init_loc='C:\\\\Users\\\\1\\\\Documents\\\\GitHub\\\\Cleavage_Energy_Manuscript\\\\train_CGCNN_model\\\\cgcnn\\\\atom_init.json',\n",
    "                              max_num_nbr=12,\n",
    "                               step=0.8,\n",
    "                              radius=4,\n",
    "                              use_voronoi=False,\n",
    "                              use_tag=False,\n",
    "                              use_fixed_info=False,\n",
    "                              use_distance=False,\n",
    "                              train_geometry = 'initial'\n",
    "                              )\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "print(SDT_out)\n",
    "structures = SDT_out[0]\n",
    "\n",
    "#Settings necessary to build the model (since they are size of vectors as inputs)\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "SDT_out = SDT.transform(docs)\n",
    "with mp.Pool(4) as pool:\n",
    "    SDT_list = list(tqdm.tqdm(pool.imap(lambda x: SDT_out[x],range(len(SDT_out)),chunksize=40),total=len(SDT_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare prediction labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = np.array([[int(docs.index(doc)), np.log(doc['cleavage_energy'])] for doc in docs])\n",
    "target_list = pd.DataFrame(target_list, columns = ['doc_index', 'cleavage_energy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into 80:20 train:test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_training, SDT_test, target_training, target_test = train_test_split(SDT_list, target_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='valid_best_')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('valid_best_params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the model and train the model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further spilt the training data into train and validate set by 8:2 ratio to avoid overfitting\n",
    "train_test_splitter = ShuffleSplit(test_size=0.2, random_state=42)\n",
    "LR_schedule = LRScheduler( batch_size=87, epoch_size=len(SDT_training), restart_period=10, t_mult=1.2)\n",
    "\n",
    "class MyNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, **kwargs):\n",
    "        y_pred = y_pred[0] if isinstance(y_pred, tuple) else y_pred  # discard the 2nd output\n",
    "        return super().get_loss(y_pred, y_true, **kwargs)\n",
    "\n",
    "## below is the sigopt best assignment\n",
    "net = MyNet(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "    batch_size=87,  \n",
    "    module__classification=False,\n",
    "    lr=np.exp(-6.465085550816676),     \n",
    "    max_epochs=300,\n",
    "    module__atom_fea_len=43,\n",
    "    module__h_fea_len=114,\n",
    "    module__n_conv=8,\n",
    "    module__n_h=3, \n",
    "    module__use_distance=False,\n",
    "    module__cutoff=100,\n",
    "    optimizer=AdamW,\n",
    "    optimizer__weight_decay=1e-2,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_train__shuffle=True, #VERY IMPORTANT\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    iterator_valid__shuffle=False, #This should be False, which is the default\n",
    "    device=device,\n",
    "   criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    train_split = ValidSplit(cv=train_test_splitter),\n",
    "    callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    ")\n",
    "\n",
    "net.initialize()\n",
    "net.fit(SDT_training,np.array(target_training[['cleavage_energy']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions and visualize the predictions with parity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {'doc_index': list(target_training['doc_index']),\n",
    "                 'type': 'train', \n",
    "                 'actual_value':np.exp(target_training['cleavage_energy']),\n",
    "                 'predicted_value':np.exp(net.predict(SDT_training).reshape(-1))}\n",
    "\n",
    "test_data = {'doc_index': list(target_test['doc_index']),\n",
    "             'type': 'test',\n",
    "            'actual_value':np.exp(target_test['cleavage_energy']),\n",
    "            'predicted_value':np.exp(net.predict(SDT_test).reshape(-1))}\n",
    "\n",
    "\n",
    "df_training = pd.DataFrame(training_data)\n",
    "df_test = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(df_training['actual_value'], df_training['predicted_value'], color='yellowgreen', \n",
    "           marker='o', alpha=0.5, label='train: MAE=%0.4f eV/$\\AA^2$, RMSE=%0.3f eV/$\\AA^2$'\\\n",
    "            %(mean_absolute_error(df_training['actual_value'], df_training['predicted_value']), \n",
    "              np.sqrt(mean_squared_error(df_training['actual_value'], df_training['predicted_value']))))\n",
    "\n",
    "ax.scatter(df_test['actual_value'], df_test['predicted_value'], color='cornflowerblue', \n",
    "           marker='o', alpha=0.5, label='test: MAE=%0.4f eV/$\\AA^2$, RMSE=%0.3f eV/$\\AA^2$'\\\n",
    "            %(mean_absolute_error(df_test['actual_value'], df_test['predicted_value']), \n",
    "              np.sqrt(mean_squared_error(df_test['actual_value'], df_test['predicted_value']))))\n",
    "\n",
    "ax.plot([min(df_training['actual_value']), max(df_training['actual_value'])-0.25], \n",
    "        [min(df_training['actual_value']), max(df_training['actual_value'])-0.25], 'k--')\n",
    "\n",
    "# format graph\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set_xlabel('DFT Energy (eV/$\\AA^2$)', fontsize=20)\n",
    "ax.set_ylabel('CGCNN predicted Energy (eV/$\\AA^2$)', fontsize=20)\n",
    "ax.set_xlim(0,0.35)\n",
    "ax.set_ylim(0,0.35)\n",
    "#ax.set_title('Multi-element ', fontsize=14) \n",
    "ax.legend(fontsize=15, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get atomic contributions trajectories\n",
    "\n",
    "We picked the ones with reasonably accurate prediction as an example, but you can loop through the test data index and make trajectories of atomic contriution for all test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_idx = np.where(np.array((abs(df_test['actual_value'] - df_test['predicted_value']))) < 0.00005)[0]\n",
    "\n",
    "for idx in visual_idx:\n",
    "    doc_idx = int(df_test.iloc[idx]['doc_index']) \n",
    "    out, atom_fea = net.forward([SDT_list[doc_idx]])\n",
    "    contributions = atom_fea.cpu().data.numpy().reshape(-1)\n",
    "    atoms = mongo.make_atoms_from_doc(docs[doc_idx])\n",
    "    atoms.set_initial_charges(np.exp(contributions))\n",
    "    atoms.write('./Traj/docs_%d.traj'%(doc_idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
